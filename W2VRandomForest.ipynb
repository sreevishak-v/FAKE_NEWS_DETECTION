{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs2sfVuNYqfW",
        "outputId": "b580c444-8cf5-46f0-dc3f-9ae11ec72b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier  # Import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import gensim.downloader as api\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load datasets\n",
        "fake = pd.read_csv(\"/content/drive/MyDrive/NLP FAKE NEWS DETECTION/nlp dfnds/Fake.csv\")\n",
        "true = pd.read_csv(\"/content/drive/MyDrive/NLP FAKE NEWS DETECTION/nlp dfnds/True.csv\")\n",
        "\n",
        "# Add category labels\n",
        "fake['category'] = 1\n",
        "true['category'] = 0\n",
        "\n",
        "# Concatenate into one dataframe\n",
        "df = pd.concat([fake, true]).reset_index(drop=True)\n",
        "\n",
        "# Balance the dataset\n",
        "df_majority = df[df['category'] == 1].sample(n=3000, random_state=42)\n",
        "df_minority = df[df['category'] == 0].sample(n=3000, random_state=42)\n",
        "df_balanced = pd.concat([df_majority, df_minority])\n",
        "\n",
        "# Shuffle the dataframe\n",
        "df = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Separate into majority and minority classes\n",
        "df_majority = df[df['category'] == 1]\n",
        "df_minority = df[df['category'] == 0]\n",
        "\n",
        "# Undersample the majority class\n",
        "df_majority_undersampled = df_majority.sample(len(df_minority), random_state=42)\n",
        "\n",
        "# Combine undersampled majority class with minority class\n",
        "df = pd.concat([df_majority_undersampled, df_minority])\n",
        "df = df[['text', 'category']]\n",
        "\n",
        "# Load SpaCy model and define stop words and punctuations\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "stop_words = nlp.Defaults.stop_words\n",
        "punctuations = string.punctuation\n",
        "\n",
        "# Load pre-trained Word2Vec embeddings\n",
        "wv = api.load('word2vec-google-news-300')\n",
        "\n",
        "# Function to tokenize and preprocess text\n",
        "def spacy_tokenizer(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    mytokens = [word.lemma_.lower().strip() for word in doc]\n",
        "    mytokens = [word for word in mytokens if word not in stop_words and word not in punctuations]\n",
        "    return mytokens\n",
        "\n",
        "# Apply tokenization to each row in 'data' column\n",
        "df['data'] = df['text'].apply(spacy_tokenizer)\n",
        "\n",
        "# Generate word vectors for each document\n",
        "df['vec'] = df['data'].apply(lambda x: np.mean([wv[token] for token in x if token in wv] or [np.zeros(wv.vector_size)], axis=0))\n",
        "\n",
        "# Prepare X (features) and y (labels)\n",
        "X = np.vstack(df['vec'])  # Convert list of arrays to a matrix\n",
        "y = df['category']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define RandomForestClassifier pipeline\n",
        "model_pipeline_rf = Pipeline([\n",
        "    ('rf', RandomForestClassifier(random_state=1))  # Use default parameters for RandomForestClassifier\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "model_pipeline_rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_rf = model_pipeline_rf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "Zkup0SxzY6rz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "precision_rf = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "recall_rf = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "f1_score_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "classification_report_rf = classification_report(y_test, y_pred_rf)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Evaluation Metrics for RandomForestClassifier Model\")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
        "print(f\"Precision: {precision_rf:.4f}\")\n",
        "print(f\"Recall: {recall_rf:.4f}\")\n",
        "print(f\"F1-score: {f1_score_rf:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report_rf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys9sW_YcZDWe",
        "outputId": "482d2a5b-825a-4122-f287-8393d8f482ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics for RandomForestClassifier Model\n",
            "---------------------------------------------------\n",
            "Accuracy: 0.9100\n",
            "Precision: 0.9109\n",
            "Recall: 0.9100\n",
            "F1-score: 0.9100\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.93      0.91       592\n",
            "           1       0.93      0.89      0.91       608\n",
            "\n",
            "    accuracy                           0.91      1200\n",
            "   macro avg       0.91      0.91      0.91      1200\n",
            "weighted avg       0.91      0.91      0.91      1200\n",
            "\n"
          ]
        }
      ]
    }
  ]
}