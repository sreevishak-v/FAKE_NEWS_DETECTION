{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32755,"status":"ok","timestamp":1719301880394,"user":{"displayName":"SREEVISHAK V","userId":"04180199107471874403"},"user_tz":-330},"id":"P61gbgLmIxCA","outputId":"fb6e64ad-d436-4262-901b-bbfa04950a9e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n"]}],"source":["!pip install transformers\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yDQYQiorJKLW"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import classification_report\n","import torch\n","import transformers as ppb\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CJJGvA6EJOfI"},"outputs":[],"source":["fake = pd.read_csv(\"/content/drive/MyDrive/NLP PROJECT/DATASET/Fake.csv\")\n","true = pd.read_csv(\"/content/drive/MyDrive/NLP PROJECT/DATASET/True.csv\")\n","# Add category labels\n","fake['category'] = 1\n","true['category'] = 0\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v_Ixd_RQWX-Z"},"outputs":[],"source":["# Concatenate datasets and reset index\n","df = pd.concat([fake, true]).reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VUeNreyWWFFy"},"outputs":[],"source":["# Separate the majority and minority classes\n","df_majority = df[df['category'] == 1]\n","df_minority = df[df['category'] == 0]\n","\n","# Sample 3000 data points from each class\n","df_majority_sampled = df_majority.sample(n=500, random_state=42)\n","df_minority_sampled = df_minority.sample(n=500, random_state=42)\n","\n","# Combine the sampled data\n","df_balanced = pd.concat([df_majority_sampled, df_minority_sampled])\n","\n","# Shuffle the dataframe\n","df= df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","# Save the balanced dataset if needed\n","# df_balanced.to_csv('balanced_dataset.csv', index=False)\n","\n","df_majority = df[df['category'] == 1]\n","df_minority = df[df['category'] == 0]\n","\n","# Undersample the majority class\n","df_majority_undersampled = df_majority.sample(len(df_minority), random_state=42)\n","\n","# Combine the undersampled majority class with the minority class\n","df = pd.concat([df_majority_undersampled, df_minority])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m4MnNhp8Wg9p"},"outputs":[],"source":["df=df[['text','category']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPrHK0e0WmAz"},"outputs":[],"source":["batch_1 = df[:1000]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1719301898811,"user":{"displayName":"SREEVISHAK V","userId":"04180199107471874403"},"user_tz":-330},"id":"MLzdyF50Wodd","outputId":"b9a35fd3-7f71-4883-f984-ea53f420a45f"},"outputs":[{"data":{"text/plain":["category\n","1    500\n","0    500\n","Name: count, dtype: int64"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["batch_1['category'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VMz43_LrWux5"},"outputs":[],"source":["model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0TksWWiBW_kr"},"outputs":[],"source":["tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n","model = model_class.from_pretrained(pretrained_weights)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DxHYe2aFXEGu"},"outputs":[],"source":["# Tokenize the data with truncation and padding to max length\n","encoded_inputs = tokenizer.batch_encode_plus(\n","    df['text'].tolist(),\n","    add_special_tokens=True,\n","    max_length=512,\n","    padding='max_length',\n","    truncation=True,\n","    return_tensors='pt'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MJgoronlXNsg"},"outputs":[],"source":["# Extract input_ids and attention_mask\n","input_ids = encoded_inputs['input_ids']\n","attention_mask = encoded_inputs['attention_mask']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1719301930608,"user":{"displayName":"SREEVISHAK V","userId":"04180199107471874403"},"user_tz":-330},"id":"oPn3YyUDXsC1","outputId":"30eee295-9e4a-4845-ae63-f5cbeca8a536"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1000, 512])\n"]}],"source":["# Verify the shape of input_ids\n","print(input_ids.shape)  # Should print (1000, 512)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GUIwEDtRXzkq"},"outputs":[],"source":["# Get the features from the model\n","with torch.no_grad():\n","    last_hidden_states = model(input_ids, attention_mask=attention_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sPiUI-XVZo0G"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"id":"i2DRHbwRZwZ7","executionInfo":{"status":"error","timestamp":1719304501940,"user_tz":-330,"elapsed":244344,"user":{"displayName":"SREEVISHAK V","userId":"04180199107471874403"}},"outputId":"d1c49369-e009-4aa5-e78b-33c56815ab89"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'Pipeline' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e5f7062a25bb>\u001b[0m in \u001b[0;36m<cell line: 73>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Create and train the Logistic Regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m model_pipeline_lr = Pipeline([\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m ])\n","\u001b[0;31mNameError\u001b[0m: name 'Pipeline' is not defined"]}],"source":["!pip install transformers\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import classification_report\n","import torch\n","import transformers as ppb\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Load datasets\n","fake = pd.read_csv(\"/content/drive/MyDrive/NLP PROJECT/DATASET/Fake.csv\")\n","true = pd.read_csv(\"/content/drive/MyDrive/NLP PROJECT/DATASET/True.csv\")\n","\n","# Add category labels\n","fake['category'] = 1\n","true['category'] = 0\n","\n","# Concatenate datasets and reset index\n","df = pd.concat([fake, true]).reset_index(drop=True)\n","\n","# Sample 500 data points from each class for the example\n","df_majority_sampled = df[df['category'] == 1].sample(n=500, random_state=42)\n","df_minority_sampled = df[df['category'] == 0].sample(n=500, random_state=42)\n","\n","# Combine the sampled data and shuffle the dataframe\n","df_balanced = pd.concat([df_majority_sampled, df_minority_sampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","# Prepare the balanced dataframe\n","df = df_balanced[['text', 'category']]\n","\n","# Load the BERT model and tokenizer\n","model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n","tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n","model = model_class.from_pretrained(pretrained_weights)\n","\n","# Function to get BERT embeddings\n","def get_bert_embeddings(text_list):\n","    encoded_inputs = tokenizer.batch_encode_plus(\n","        text_list,\n","        add_special_tokens=True,\n","        max_length=512,\n","        padding='max_length',\n","        truncation=True,\n","        return_tensors='pt'\n","    )\n","    input_ids = encoded_inputs['input_ids']\n","    attention_mask = encoded_inputs['attention_mask']\n","    with torch.no_grad():\n","        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n","    return last_hidden_states[0][:,0,:].numpy()  # Use the [CLS] token representation\n","\n","# Process data in batches\n","batch_size = 50\n","embeddings = []\n","\n","for i in range(0, len(df), batch_size):\n","    batch_texts = df['text'][i:i + batch_size].tolist()\n","    batch_embeddings = get_bert_embeddings(batch_texts)\n","    embeddings.append(batch_embeddings)\n","\n","# Combine all batch embeddings\n","X = np.vstack(embeddings)\n","y = df['category'].values\n","\n","# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=1)\n","\n","# Create and train the Logistic Regression model\n","model_pipeline_lr = Pipeline([\n","    ('lr', LogisticRegression(max_iter=1000, random_state=1))\n","])\n","model_pipeline_lr.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred_lr = model_pipeline_lr.predict(X_test)\n","\n","# Evaluate the model\n","accuracy_lr = accuracy_score(y_test, y_pred_lr)\n","precision_lr = precision_score(y_test, y_pred_lr, average='weighted')\n","recall_lr = recall_score(y_test, y_pred_lr, average='weighted')\n","f1_score_lr = f1_score(y_test, y_pred_lr, average='weighted')\n","classification_report_lr = classification_report(y_test, y_pred_lr)\n","\n","# Print evaluation metrics\n","print(\"Evaluation Metrics for Logistic Regression Model\")\n","print(\"------------------------------------------------\")\n","print(f\"Accuracy: {accuracy_lr:.4f}\")\n","print(f\"Precision: {precision_lr:.4f}\")\n","print(f\"Recall: {recall_lr:.4f}\")\n","print(f\"F1-score: {f1_score_lr:.4f}\")\n","print(\"Classification Report:\")\n","print(classification_report_lr)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26841,"status":"ok","timestamp":1719301296961,"user":{"displayName":"SREEVISHAK V","userId":"04180199107471874403"},"user_tz":-330},"id":"vOJjptk9JTu6","outputId":"4f2090e4-ffe1-4816-d4ca-4a9752080105"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}