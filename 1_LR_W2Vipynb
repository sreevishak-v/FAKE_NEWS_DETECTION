{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"UD4xyhtrBTCn"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import spacy\n","import string\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","import gensim.downloader as api"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2GgXUFhBX50","executionInfo":{"status":"ok","timestamp":1719262381274,"user_tz":-330,"elapsed":3934,"user":{"displayName":"SREEVISHAK V","userId":"04180199107471874403"}},"outputId":"02daaf15-a8fb-405c-8284-8ecb9362e7de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["fake= pd.read_csv(\"/content/drive/MyDrive/NLP PROJECT/DATASET/Fake.csv\")\n","true= pd.read_csv(\"/content/drive/MyDrive/NLP PROJECT/DATASET/True.csv\")"],"metadata":{"id":"1QpGN3AKBeqO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fake['category']=1\n","true['category']=0\n","\n","df=pd.concat([fake,true]).reset_index(drop=True)\n"],"metadata":{"id":"oLg-x20TB8DG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Separate the majority and minority classes\n","df_majority = df[df['category'] == 1]\n","df_minority = df[df['category'] == 0]\n","\n","# Sample 3000 data points from each class\n","df_majority_sampled = df_majority.sample(n=3000, random_state=42)\n","df_minority_sampled = df_minority.sample(n=3000, random_state=42)\n","\n","# Combine the sampled data\n","df_balanced = pd.concat([df_majority_sampled, df_minority_sampled])\n","\n","# Shuffle the dataframe\n","df= df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","# Save the balanced dataset if needed\n","# df_balanced.to_csv('balanced_dataset.csv', index=False)"],"metadata":{"id":"ZUlVQ12kB-nz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_majority = df[df['category'] == 1]\n","df_minority = df[df['category'] == 0]\n","\n","# Undersample the majority class\n","df_majority_undersampled = df_majority.sample(len(df_minority), random_state=42)\n","\n","# Combine the undersampled majority class with the minority class\n","df = pd.concat([df_majority_undersampled, df_minority])\n","df=df[['text','category']]"],"metadata":{"id":"M-GR-At_CEZr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load SpaCy model and define stop words and punctuations\n","nlp = spacy.load(\"en_core_web_sm\")\n","stop_words = nlp.Defaults.stop_words\n","punctuations = string.punctuation\n"],"metadata":{"id":"LWPzJLT1CMsx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load pre-trained Word2Vec embeddings\n","wv = api.load('word2vec-google-news-300')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OFlg8FW6CQip","executionInfo":{"status":"ok","timestamp":1719263456825,"user_tz":-330,"elapsed":875796,"user":{"displayName":"SREEVISHAK V","userId":"04180199107471874403"}},"outputId":"11f93dd0-ff81-467e-ad0a-882e37d99c6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"]}]},{"cell_type":"code","source":["# Function to tokenize and preprocess text\n","def spacy_tokenizer(sentence):\n","    # Creating our token object, which is used to create documents with linguistic annotations.\n","    doc = nlp(sentence)\n","\n","    # Lemmatizing each token and converting each token into lowercase\n","    mytokens = [word.lemma_.lower().strip() for word in doc]\n","\n","    # Removing stop words and punctuations\n","    mytokens = [word for word in mytokens if word not in stop_words and word not in punctuations]\n","\n","    # Return preprocessed list of tokens\n","    return mytokens"],"metadata":{"id":"LGGhIV4RCTUb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply tokenization to each row in 'data' column\n","df['data'] = df['text'].apply(spacy_tokenizer)"],"metadata":{"id":"AB7PAKpWGbwS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate word vectors for each document\n","df['vec'] = df['data'].apply(lambda x: np.mean([wv[token] for token in x if token in wv] or [np.zeros(wv.vector_size)], axis=0))"],"metadata":{"id":"YTC2Z4ugGrEX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = np.vstack(df['vec'])  # Convert list of arrays to a matrix\n","y = df['category']"],"metadata":{"id":"FOy6A77rHJI4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=1)"],"metadata":{"id":"of-ex9yvHAgw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_pipeline_lr = Pipeline([\n","    ('lr', LogisticRegression(max_iter=1000))  # Increase max_iter to 1000 or more\n","])\n","\n","# Train the model\n","model_pipeline_lr.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred_lr = model_pipeline_lr.predict(X_test)"],"metadata":{"id":"KhPT96jBJG3t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy_lr = accuracy_score(y_test, y_pred_lr)\n","precision_lr = precision_score(y_test, y_pred_lr, average='weighted')\n","recall_lr = recall_score(y_test, y_pred_lr, average='weighted')\n","f1_score_lr = f1_score(y_test, y_pred_lr, average='weighted')\n","classification_report_lr = classification_report(y_test, y_pred_lr)\n","\n","# Print evaluation metrics\n","print(\"Accuracy:\", accuracy_lr)\n","print(\"Precision:\", precision_lr)\n","print(\"Recall:\", recall_lr)\n","print(\"F1 Score:\", f1_score_lr)\n","print(\"Evaluation Metrics for Logistic Regression Model\")\n","print(\"------------------------------------------------\")\n","print(classification_report_lr)"],"metadata":{"id":"JU-g1MOQJJs6","executionInfo":{"status":"ok","timestamp":1719264389659,"user_tz":-330,"elapsed":503,"user":{"displayName":"SREEVISHAK V","userId":"04180199107471874403"}},"outputId":"c88071e5-cbb9-4dd3-ceb0-0e45f176bdef","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9266666666666666\n","Precision: 0.927783724043807\n","Recall: 0.9266666666666666\n","F1 Score: 0.9266452748661159\n","Evaluation Metrics for Logistic Regression Model\n","------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.95      0.93       592\n","           1       0.95      0.90      0.93       608\n","\n","    accuracy                           0.93      1200\n","   macro avg       0.93      0.93      0.93      1200\n","weighted avg       0.93      0.93      0.93      1200\n","\n"]}]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}